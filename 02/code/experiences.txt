General
=======
About 5 hours for exercise 1 (includes revamping of code from sheet 1 that was bad).
About 3-4 hours for exercise 2+3.
The corresponding lecture was easy to follow for the most part. As for the "plausibility argument for BM25" ... I got the gist of it I guess.


Exercise 2
==========

testing k, constant b=0.75

k     | "star wars parody" | "chinese fighting movie" | <almost all requests>
------+--------------------+--------------------------+-----------------------
1.2   | 3 valid results    | results 1, 2 valid       | identical for all 3
      |                    |                          |
1.75  | 3 valid results    | results 1, 2 valid       |
      |                    |                          |
2     | 1 valid result     | results 1, 3 valid       |
------+--------------------+--------------------------+-----------------------

Setting k too high, in some cases results where important keywords are missing got high ratings.
Therefore going with k=1.2.


testing b, constant k=1.2

b     | "men in black"     | "terminator sequel"      | <almost all requests>
------+--------------------+--------------------------+-----------------------
0.25  | 3 valid results    | results 1, 2 valid       | identical for all 3
      |                    |                          |
0.5   | 3 valid results    | results 1, 2 valid       |
      |                    |                          |
0.75  | results 1, 3 valid | results 1, 3 valid       |
------+--------------------+--------------------------+-----------------------

It's hard to find queries where the quality of results differs in any significant and/or understandable way.
Going with b=0.5.

Also addded filtering of stopwords.

Looking back (after having done exercise 3), I should've used an ouput of more than 3 results to test k and b values.
